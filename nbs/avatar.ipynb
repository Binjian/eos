{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901b4b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Title: avatar\n",
    "Author: [Binjian Xin](https://www.newrizon.com)\n",
    "Date created: 2022/12/14\n",
    "Last modified: 2022/12/14\n",
    "Description: Implement realtime reinforcement learning algorithm for training and inference\n",
    "convergence of ddpg and rdpg agent\n",
    "## Introduction\n",
    "\n",
    "This script shows an implementation of rl agent on EC1 truck real environment.\n",
    "\n",
    "\n",
    "An Ego Vehicle drives through a fixed track and collect loss (negative reward) defined\n",
    "as energy consumption\n",
    "\n",
    "\"\"\"\n",
    "from __future__ import annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5bc330",
   "metadata": {},
   "outputs": [],
   "source": [
    "import abc\n",
    "import argparse\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75dd5be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logging\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df97a5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# system imports\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69d7609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# third party imports\n",
    "from dataclasses import dataclass\n",
    "from logging.handlers import SocketHandler\n",
    "from pathlib import Path, PurePosixPath\n",
    "from threading import Event\n",
    "from typing import Optional, Union, cast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61f2e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt  # type: ignore\n",
    "import numpy as np\n",
    "import pandas as pd  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6023c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.debugging.set_log_device_placement(True)\n",
    "# visualization import\n",
    "import tensorflow as tf\n",
    "from git import Repo\n",
    "from pythonjsonlogger import jsonlogger  # type: ignore\n",
    "from tensorflow.summary import SummaryWriter, create_file_writer, scalar  # type: ignore\n",
    "from typeguard import check_type  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea857c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from eos import proj_root\n",
    "from eos.agent import DDPG, DPG, RDPG\n",
    "from eos.agent.utils import HyperParamDDPG, HyperParamRDPG\n",
    "from eos.data_io.config import (\n",
    "    TruckInField,\n",
    "    TruckInCloud,\n",
    "    Driver,\n",
    "    CANMessenger,\n",
    "    TripMessenger,\n",
    "    str_to_can_server,\n",
    "    str_to_driver,\n",
    "    str_to_trip_server,\n",
    "    str_to_truck,\n",
    ")\n",
    "from eos.data_io.dataflow import (\n",
    "    Cloud,\n",
    "    Cruncher,\n",
    "    Kvaser,\n",
    "    Pipeline,\n",
    ")\n",
    "from eos.data_io.utils import set_root_logger, GracefulKiller"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466c246e",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf5c57a",
   "metadata": {},
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"] = \"true\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81aa3bbb",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "system warnings and numpy warnings handling\n",
    "np.warnings.filterwarnings('ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c741bae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(kw_only=True)\n",
    "class Avatar(abc.ABC):\n",
    "    _truck: Union[TruckInField, TruckInCloud]\n",
    "    _driver: Driver\n",
    "    _can_server: CANMessenger\n",
    "    _trip_server: Optional[TripMessenger]\n",
    "    _agent: DPG  # set by derived Avatar like AvatarDDPG\n",
    "    logger: logging.Logger\n",
    "    dict_logger: dict\n",
    "    vehicle_interface: Union[Kvaser, Cloud] = None\n",
    "    _resume: bool = True\n",
    "    _infer_mode: bool = False\n",
    "    cruncher: Optional[Cruncher] = None\n",
    "    data_root: Path = Path(\".\") / \"data\"\n",
    "    log_root: Optional[Path] = None\n",
    "\n",
    "    def __post_init__(\n",
    "        self,\n",
    "    ) -> None:\n",
    "        self.repo = Repo(proj_root)\n",
    "        # assert self.repo.is_dirty() == False, \"Repo is dirty, please commit first\"\n",
    "        short_sha = self.repo.git.rev_parse(self.repo.head.commit.hexsha, short=7)\n",
    "        self.logger.info(\n",
    "            f\"Project root: {proj_root}, \"  # type: ignore\n",
    "            f\"git head: {short_sha}, \"\n",
    "            f\"author: {self.repo.head.commit.author.name}, \"\n",
    "            f\"git message: {self.repo.head.commit.message}\",\n",
    "            extra=self.dict_logger,\n",
    "        )\n",
    "\n",
    "        self.logger.info(f\"{{'vehicle': '{self.truck.vid}'}}\", extra=self.dict_logger)\n",
    "        self.logger.info(f\"{{'driver': '{self.driver.pid}'}}\", extra=self.dict_logger)\n",
    "\n",
    "        self.eps = np.finfo(\n",
    "            np.float32\n",
    "        ).eps.item()  # smallest number such that 1.0 + eps != 1.0\n",
    "\n",
    "        self.logger.info(\n",
    "            f\"{{'header': 'Num GPUs Available: {len(tf.config.list_physical_devices('GPU'))}'}}\"\n",
    "        )\n",
    "        # gpus = tf.config.list_physical_devices(device_type=\"GPU\")\n",
    "        # tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "        self.logger.info(f\"Tensorflow version: {tf.__version__}\")\n",
    "        tf_sys_details = tf.sysconfig.get_build_info()\n",
    "        self.logger.info(f\"{{'header': 'Tensorflow build info: {tf_sys_details}'}}\")\n",
    "\n",
    "        tf.keras.backend.set_floatx(\"float32\")\n",
    "        self.logger.info(\n",
    "            f\"{{'header': 'tensorflow device lib:\\n{tf.config.list_physical_devices()}'}}\",\n",
    "            extra=self.dict_logger,\n",
    "        )\n",
    "        self.logger.info(\n",
    "            f\"{{'header': 'Tensorflow Imported!'}}\", extra=self.dict_logger\n",
    "        )\n",
    "\n",
    "        if self.can_server.protocol == \"udp\":\n",
    "            self.vehicle_interface: Kvaser = Kvaser(  # Producer~Consumer~Filter\n",
    "                truck=cast(TruckInField, self.truck),\n",
    "                driver=self.driver,\n",
    "                can_server=self.can_server,\n",
    "                resume=self.resume,\n",
    "                data_dir=self.data_root,\n",
    "                logger=self.logger,\n",
    "                dict_logger=self.dict_logger,\n",
    "            )\n",
    "        else:  # self.can_server.protocol == 'tcp'\n",
    "            self.vehicle_interface: Cloud = Cloud(  # Producer~Consumer\n",
    "                truck=cast(TruckInCloud, self.truck),\n",
    "                driver=self.driver,\n",
    "                can_server=self.can_server,\n",
    "                trip_server=self.trip_server,\n",
    "                resume=self.resume,\n",
    "                data_dir=self.data_root,\n",
    "                logger=self.logger,\n",
    "                dict_logger=self.dict_logger,\n",
    "            )\n",
    "\n",
    "        self.cruncher = Cruncher(  # Consumer\n",
    "            agent=self.agent,\n",
    "            truck=self.truck,\n",
    "            driver=self.driver,\n",
    "            resume=self.resume,\n",
    "            infer_mode=self.infer_mode,\n",
    "            data_dir=self.data_root,\n",
    "            logger=self.logger,\n",
    "            dict_logger=self.dict_logger,\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def agent(self) -> Optional[DPG]:\n",
    "        return self._agent\n",
    "\n",
    "    @agent.setter\n",
    "    def agent(self, value: DPG) -> None:\n",
    "        self._agent = value\n",
    "\n",
    "    @property\n",
    "    def truck(self) -> Union[TruckInField, TruckInCloud]:\n",
    "        return self._truck\n",
    "\n",
    "    @truck.setter\n",
    "    def truck(self, value: Union[TruckInField, TruckInCloud]) -> None:\n",
    "        self._truck = value\n",
    "\n",
    "    @property\n",
    "    def driver(self) -> Driver:\n",
    "        return self._driver\n",
    "\n",
    "    @driver.setter\n",
    "    def driver(self, value: Driver) -> None:\n",
    "        self._driver = value\n",
    "\n",
    "    @property\n",
    "    def can_server(self) -> CANMessenger:\n",
    "        return self._can_server\n",
    "\n",
    "    @can_server.setter\n",
    "    def can_server(self, value: CANMessenger) -> None:\n",
    "        self._can_server = value\n",
    "\n",
    "    @property\n",
    "    def trip_server(self) -> TripMessenger:\n",
    "        return self._trip_server\n",
    "\n",
    "    @trip_server.setter\n",
    "    def trip_server(self, value: TripMessenger) -> None:\n",
    "        self._trip_server = value\n",
    "\n",
    "    @property\n",
    "    def resume(self) -> bool:\n",
    "        return self._resume\n",
    "\n",
    "    @resume.setter\n",
    "    def resume(self, value: bool) -> None:\n",
    "        self._resume = value\n",
    "\n",
    "    @property\n",
    "    def infer_mode(self) -> bool:\n",
    "        return self._infer_mode\n",
    "\n",
    "    @infer_mode.setter\n",
    "    def infer_mode(self, value: bool) -> None:\n",
    "        self._infer_mode = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fdbe97",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \"\"\"\n",
    "    ## Setup\n",
    "    \"\"\"\n",
    "    # resumption settings\n",
    "    parser = argparse.ArgumentParser(\n",
    "        \"Use RL agent (DDPG or RDPG) with tensorflow backend for EOS with coast-down activated \"\n",
    "        \"and expected velocity in 3 seconds\"\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"-v\",\n",
    "        \"--vehicle\",\n",
    "        type=str,\n",
    "        default=\"VB7_FIELD\",\n",
    "        help=\"vehicle ID like 'VB7' or 'MP3' or VIN 'HMZABAAH1MF011055'\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-d\",\n",
    "        \"--driver\",\n",
    "        type=str,\n",
    "        default=\"wang-kai\",\n",
    "        help=\"driver ID like 'longfei.zheng' or 'jiangbo.wei'\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-i\",\n",
    "        \"--interface\",\n",
    "        type=str,\n",
    "        default=\"can_udp_svc\",\n",
    "        help=\"url for remote can server, e.g. 10.10.0.6:30865, or name, e.g. can_cloud, can_intra, can_udp_svc\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-t\",\n",
    "        \"--trip\",\n",
    "        type=str,\n",
    "        default=\"local_udp\",\n",
    "        help=\"trip messenger, url or name, e.g. rocket_cloud, local_udp\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-c\",\n",
    "        \"--control\",\n",
    "        type=str,\n",
    "        default=\"UDP\",\n",
    "        help=\"HMI Control Interface: \"\n",
    "        \"'RMQ' for mobile phone (using rocketmq for training/assessment); \"\n",
    "        \"'UDP' for local hmi (using loopback tcp for training/assessment); \"\n",
    "        \"'DUMMY' for non-interaction for inference only and testing purpose\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-a\",\n",
    "        \"--agent\",\n",
    "        type=str,\n",
    "        default=\"ddpg\",\n",
    "        help=\"RL agent choice: 'ddpg' for DDPG; 'rdpg' for Recurrent DPG\",\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"-r\",\n",
    "        \"--resume\",\n",
    "        default=True,\n",
    "        help=\"resume the last training with restored model, checkpoint and pedal map\",\n",
    "        action=\"store_true\",\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"-l\",\n",
    "        \"--learning\",\n",
    "        default=True,\n",
    "        help=\"True for learning , with model update and training. False for inference only\",\n",
    "        action=\"store_true\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-p\",\n",
    "        \"--path\",\n",
    "        type=str,\n",
    "        default=\".\",\n",
    "        help=\"relative path to be saved, for create sub-folder for different drivers\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-o\",\n",
    "        \"--output\",\n",
    "        type=str,\n",
    "        default=\"mongo_local\",\n",
    "        help=\"pool selection for data storage, \"\n",
    "        \"url for mongodb server in format usr:password@host:port, e.g. admint:y02ydhVqDj3QFjT@10.10.0.4:23000, \"\n",
    "        \"or simply name with synced default config, e.g. mongo_cluster, mongo_local; \"\n",
    "        \"if specified as path name, use dask local under proj_root/data folder or cluster\",\n",
    "    )\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # set up data folder (logging, checkpoint, table)\n",
    "    try:\n",
    "        truck: Union[TruckInField, TruckInCloud] = str_to_truck(args.vehicle)\n",
    "    except KeyError:\n",
    "        raise KeyError(f\"vehicle {args.vehicle} not found in config file\")\n",
    "    else:\n",
    "        print(f\"Vehicle found. vid:{truck.vid}, vin: {truck.vin}.\")\n",
    "\n",
    "    try:\n",
    "        driver: Driver = str_to_driver(args.driver)\n",
    "    except KeyError:\n",
    "        raise KeyError(f\"driver {args.driver} not found in config file\")\n",
    "    else:\n",
    "        print(f\"Driver found. pid:{driver.pid}, name: {driver.name}.\")\n",
    "\n",
    "    # remotecan_srv: str = 'can_intra'\n",
    "    try:\n",
    "        can_server = str_to_can_server(args.interface)\n",
    "    except KeyError:\n",
    "        raise KeyError(f\"can server {args.interface} not found in config file\")\n",
    "    else:\n",
    "        print(f\"CAN Server found: {can_server.server_name}\")\n",
    "\n",
    "    try:\n",
    "        trip_server = str_to_trip_server(args.trip)\n",
    "    except KeyError:\n",
    "        raise KeyError(f\"trip server {args.web} not found in config file\")\n",
    "    else:\n",
    "        print(f\"Trip Server found: {trip_server.server_name}\")\n",
    "\n",
    "    assert args.agent in [\"ddpg\", \"rdpg\"], \"agent must be either ddpg or rdpg\"\n",
    "\n",
    "    if args.resume:\n",
    "        data_root = proj_root.joinpath(\"data/\" + truck.vin + \"-\" + driver.pid).joinpath(\n",
    "            args.path\n",
    "        )\n",
    "    else:  # from scratch\n",
    "        data_root = proj_root.joinpath(\n",
    "            \"data/scratch\" + truck.vin + \"-\" + driver.pid\n",
    "        ).joinpath(args.data_path)\n",
    "\n",
    "    logger, dict_logger = set_root_logger(\n",
    "        name=\"eos\",\n",
    "        data_root=data_root,\n",
    "        agent=args.agent,\n",
    "        tz = truck.site.tz,\n",
    "        truck = truck.vid,\n",
    "        driver = driver.pid\n",
    "    )\n",
    "    logger.info(f\"{{'header': 'Start Logging'}}\", extra=dict_logger)\n",
    "\n",
    "    if args.agent == \"ddpg\":\n",
    "        agent: DDPG = DDPG(\n",
    "            _coll_type=\"RECORD\",\n",
    "            _hyper_param=HyperParamDDPG(),\n",
    "            _truck=truck,\n",
    "            _driver=driver,\n",
    "            _pool_key=args.output,\n",
    "            _data_folder=str(data_root),\n",
    "            _infer_mode=(not args.learning),\n",
    "            _resume=args.resume,\n",
    "            logger=logger,\n",
    "            dict_logger=dict_logger,\n",
    "        )\n",
    "    else:  # args.agent == 'rdpg':\n",
    "        agent: RDPG = RDPG(  # type: ignore\n",
    "            _coll_type=\"EPISODE\",\n",
    "            _hyper_param=HyperParamRDPG(),\n",
    "            _truck=truck,\n",
    "            _driver=driver,\n",
    "            _pool_key=args.output,\n",
    "            _data_folder=str(data_root),\n",
    "            _infer_mode=(not args.learning),\n",
    "            _resume=args.resume,\n",
    "            logger=logger,\n",
    "            dict_logger=dict_logger,\n",
    "        )\n",
    "\n",
    "    try:\n",
    "        avatar = Avatar(\n",
    "            _truck=truck,\n",
    "            _driver=driver,\n",
    "            _agent=agent,\n",
    "            _can_server=can_server,\n",
    "            _trip_server=trip_server,\n",
    "            logger=logger,\n",
    "            dict_logger=dict_logger,\n",
    "            _resume=args.resume,\n",
    "            _infer_mode=(not args.learning),\n",
    "            data_root=data_root,\n",
    "        )\n",
    "    except TypeError as e:\n",
    "        logger.error(\n",
    "            f\"{{'header': 'Project Exception TypeError', \" f\"'exception': '{e}'}}\",\n",
    "            extra=dict_logger,\n",
    "        )\n",
    "        sys.exit(1)\n",
    "    except Exception as e:\n",
    "        logger.error(\n",
    "            f\"{{'header': 'main Exception', \" f\"'exception': '{e}'}}\",\n",
    "            extra=dict_logger,\n",
    "        )\n",
    "        sys.exit(1)\n",
    "\n",
    "    # initialize dataflow: pipelines, sync events among the threads\n",
    "    observe_pipeline = Pipeline[pd.DataFrame](\n",
    "        maxsize=3\n",
    "    )  # pipeline for observations (type dataframe)\n",
    "    flash_pipeline = Pipeline[pd.DataFrame](\n",
    "        maxsize=3\n",
    "    )  # pipeline for flashing torque tables (type dataframe)\n",
    "    start_event = Event()\n",
    "    stop_event = Event()\n",
    "    interrupt_event = Event()\n",
    "    exit_event = Event()\n",
    "    flash_event = Event()\n",
    "\n",
    "    logger.info(f\"{{'header': 'main Thread Pool starts!'}}\", extra=dict_logger)\n",
    "\n",
    "    # Gracefulkiller instance can be created only in the main thread!\n",
    "    killer = GracefulKiller(exit_event)\n",
    "    with concurrent.futures.ThreadPoolExecutor(\n",
    "        max_workers=2, thread_name_prefix='Avatar'\n",
    "    ) as executor:\n",
    "        executor.submit(\n",
    "            avatar.vehicle_interface.ignite,  # observe thread (spawns 4 threads for input, HMI and output)\n",
    "            observe_pipeline,  # input port; output\n",
    "            flash_pipeline,  # out port; input\n",
    "            start_event,\n",
    "            stop_event,\n",
    "            interrupt_event,\n",
    "            flash_event,\n",
    "            exit_event,\n",
    "        )\n",
    "\n",
    "        executor.submit(\n",
    "            avatar.cruncher.filter,  # data crunch thread\n",
    "            observe_pipeline,  # output port; input\n",
    "            flash_pipeline,  # input port; output\n",
    "            start_event,\n",
    "            stop_event,\n",
    "            interrupt_event,\n",
    "            flash_event,\n",
    "            exit_event,\n",
    "        )\n",
    "\n",
    "    logger.info(f\"{{'header': 'Start main Thread Pool dies!'}}\", extra=dict_logger)\n",
    "    # default behavior is \"observe\" will start and send out all the events to orchestrate other three threads.\n",
    "    logger.info(\"Program exit!\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
