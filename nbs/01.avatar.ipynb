{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "528ed6cb7612aca7",
   "metadata": {},
   "source": [
    "# Avatar\n",
    "\n",
    "> Avatar class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fcd3cdf6e16820",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp avatar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7f179d5a79eea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from __future__ import annotations\n",
    "from nbdev.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa7e68346899fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import abc\n",
    "import argparse\n",
    "import concurrent.futures\n",
    "\n",
    "import logging\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from logging.handlers import SocketHandler\n",
    "from pathlib import Path, PurePosixPath\n",
    "from threading import Event\n",
    "from typing import Optional, Union, cast\n",
    "import matplotlib.pyplot as plt  # type: ignore\n",
    "import numpy as np\n",
    "import pandas as pd  # type: ignore\n",
    "import tensorflow as tf\n",
    "from git import Repo\n",
    "from pythonjsonlogger import jsonlogger  # type: ignore\n",
    "from tensorflow.summary import SummaryWriter, create_file_writer, scalar  # type: ignore\n",
    "from typeguard import check_type  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836a5f98f8305f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from tspace.agent.dpg import DPG\n",
    "from tspace.agent.ddpg import DDPG \n",
    "from tspace.agent.rdpg.rdpg import RDPG\n",
    "from tspace.agent.utils.hyperparams import HyperParamDDPG, HyperParamRDPG\n",
    "\n",
    "from tspace.config.vehicles import TruckInField, TruckInCloud\n",
    "from tspace.config.drivers import Driver\n",
    "from tspace.config.messengers import CANMessenger, TripMessenger\n",
    "from tspace.config.utils import ( \n",
    "    str_to_can_server, \n",
    "    str_to_driver,\n",
    "    str_to_trip_server,\n",
    "    str_to_truck,\n",
    ")\n",
    "\n",
    "from tspace.dataflow.cloud import Cloud\n",
    "from tspace.dataflow.cruncher import Cruncher\n",
    "from tspace.dataflow.kvaser import Kvaser\n",
    "from tspace.dataflow.pipeline.queue import Pipeline\n",
    "from tspace.system.log import set_root_logger\n",
    "from tspace.system.graceful_killer import GracefulKiller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2658ec29a3292755",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "repo = Repo('.', search_parent_directories=True)\n",
    "proj_root = Path(repo.working_tree_dir)\n",
    "proj_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb2ec0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "short_sha = repo.git.rev_parse(repo.head.commit.hexsha, short=7)\n",
    "repo.head.commit.author.name\n",
    "repo.head.commit.message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b60253770a70ac2",
   "metadata": {},
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e213d9c6473a717",
   "metadata": {},
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"] = \"true\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f8f86667242e8e",
   "metadata": {},
   "source": [
    "system warnings and numpy warnings handling\n",
    "np.warnings.filterwarnings('ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f33fe3baf201fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@dataclass(kw_only=True)\n",
    "class Avatar(abc.ABC):\n",
    "    \"\"\"\n",
    "    Description: Implement realtime reinforcement learning algorithm for     training and inference convergence of ddpg and rdpg agent\n",
    "    \n",
    "    Args:\n",
    "        _truck: TruckInField or TruckInCloud\n",
    "        _driver: Driver\n",
    "        _agent: DDPG or RDPG\n",
    "        _can_server: CANMessenger\n",
    "        _trip_server: TripMessenger\n",
    "        _resume: bool\n",
    "        _infer_mode: bool\n",
    "        logger: logging.Logger\n",
    "        dict_logger: dict\n",
    "        data_root: Path\n",
    "        log_root: Optional[Path]\n",
    "    \"\"\"\n",
    "    \n",
    "    _truck: Union[TruckInField, TruckInCloud]\n",
    "    _driver: Driver\n",
    "    _can_server: CANMessenger\n",
    "    _trip_server: Optional[TripMessenger]\n",
    "    _agent: DPG  # set by derived Avatar like AvatarDDPG\n",
    "    logger: logging.Logger\n",
    "    dict_logger: dict\n",
    "    vehicle_interface: Union[Kvaser, Cloud] = None\n",
    "    _resume: bool = True\n",
    "    _infer_mode: bool = False\n",
    "    cruncher: Optional[Cruncher] = None\n",
    "    data_root: Path = Path(\".\") / \"data\"\n",
    "    log_root: Optional[Path] = None\n",
    "\n",
    "    def __post_init__(\n",
    "        self,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Initialize logging, vehicle interface (Kvaser or Cloud), cruncher. \n",
    "        \n",
    "        Agent should have been initialized and passed in as argument.\n",
    "        \"\"\"\n",
    "        self.repo = repo\n",
    "        # assert self.repo.is_dirty() == False, \"Repo is dirty, please commit first\"\n",
    "        short_sha = self.repo.git.rev_parse(self.repo.head.commit.hexsha, short=7)\n",
    "        self.logger.info(\n",
    "            f\"Project root: {proj_root}, \"  # type: ignore\n",
    "            f\"git head: {short_sha}, \"\n",
    "            f\"author: {self.repo.head.commit.author.name}, \"\n",
    "            f\"git message: {self.repo.head.commit.message}\",\n",
    "            extra=self.dict_logger,\n",
    "        )\n",
    "\n",
    "        self.logger.info(f\"{{'vehicle': '{self.truck.vid}'}}\", extra=self.dict_logger)\n",
    "        self.logger.info(f\"{{'driver': '{self.driver.pid}'}}\", extra=self.dict_logger)\n",
    "\n",
    "        self.eps = np.finfo(\n",
    "            np.float32\n",
    "        ).eps.item()  # smallest number such that 1.0 + eps != 1.0\n",
    "\n",
    "        self.logger.info(\n",
    "            f\"{{'header': 'Num GPUs Available: {len(tf.config.list_physical_devices('GPU'))}'}}\"\n",
    "        )\n",
    "        # gpus = tf.config.list_physical_devices(device_type=\"GPU\")\n",
    "        # tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "        self.logger.info(f\"Tensorflow version: {tf.__version__}\")\n",
    "        tf_sys_details = tf.sysconfig.get_build_info()\n",
    "        self.logger.info(f\"{{'header': 'Tensorflow build info: {tf_sys_details}'}}\")\n",
    "\n",
    "        tf.keras.backend.set_floatx(\"float32\")\n",
    "        self.logger.info(\n",
    "            f\"{{'header': 'tensorflow device lib:\\n{tf.config.list_physical_devices()}'}}\",\n",
    "            extra=self.dict_logger,\n",
    "        )\n",
    "        self.logger.info(\n",
    "            f\"{{'header': 'Tensorflow Imported!'}}\", extra=self.dict_logger\n",
    "        )\n",
    "\n",
    "        if self.can_server.protocol == \"udp\":\n",
    "            self.vehicle_interface: Kvaser = Kvaser(  # Producer~Consumer~Filter\n",
    "                truck=cast(TruckInField, self.truck),\n",
    "                driver=self.driver,\n",
    "                can_server=self.can_server,\n",
    "                resume=self.resume,\n",
    "                data_dir=self.data_root,\n",
    "                logger=self.logger,\n",
    "                dict_logger=self.dict_logger,\n",
    "            )\n",
    "        else:  # self.can_server.protocol == 'tcp'\n",
    "            self.vehicle_interface: Cloud = Cloud(  # Producer~Consumer\n",
    "                truck=cast(TruckInCloud, self.truck),\n",
    "                driver=self.driver,\n",
    "                can_server=self.can_server,\n",
    "                trip_server=self.trip_server,\n",
    "                resume=self.resume,\n",
    "                data_dir=self.data_root,\n",
    "                logger=self.logger,\n",
    "                dict_logger=self.dict_logger,\n",
    "            )\n",
    "\n",
    "        self.cruncher = Cruncher(  # Consumer\n",
    "            agent=self.agent,\n",
    "            truck=self.truck,\n",
    "            driver=self.driver,\n",
    "            resume=self.resume,\n",
    "            infer_mode=self.infer_mode,\n",
    "            data_dir=self.data_root,\n",
    "            logger=self.logger,\n",
    "            dict_logger=self.dict_logger,\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def agent(self) -> Optional[DPG]:\n",
    "        return self._agent\n",
    "\n",
    "    @agent.setter\n",
    "    def agent(self, value: DPG) -> None:\n",
    "        self._agent = value\n",
    "\n",
    "    @property\n",
    "    def truck(self) -> Union[TruckInField, TruckInCloud]:\n",
    "        return self._truck\n",
    "\n",
    "    @truck.setter\n",
    "    def truck(self, value: Union[TruckInField, TruckInCloud]) -> None:\n",
    "        self._truck = value\n",
    "\n",
    "    @property\n",
    "    def driver(self) -> Driver:\n",
    "        return self._driver\n",
    "\n",
    "    @driver.setter\n",
    "    def driver(self, value: Driver) -> None:\n",
    "        self._driver = value\n",
    "\n",
    "    @property\n",
    "    def can_server(self) -> CANMessenger:\n",
    "        return self._can_server\n",
    "\n",
    "    @can_server.setter\n",
    "    def can_server(self, value: CANMessenger) -> None:\n",
    "        self._can_server = value\n",
    "\n",
    "    @property\n",
    "    def trip_server(self) -> TripMessenger:\n",
    "        return self._trip_server\n",
    "\n",
    "    @trip_server.setter\n",
    "    def trip_server(self, value: TripMessenger) -> None:\n",
    "        self._trip_server = value\n",
    "\n",
    "    @property\n",
    "    def resume(self) -> bool:\n",
    "        return self._resume\n",
    "\n",
    "    @resume.setter\n",
    "    def resume(self, value: bool) -> None:\n",
    "        self._resume = value\n",
    "\n",
    "    @property\n",
    "    def infer_mode(self) -> bool:\n",
    "        return self._infer_mode\n",
    "\n",
    "    @infer_mode.setter\n",
    "    def infer_mode(self, value: bool) -> None:\n",
    "        self._infer_mode = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947a5e550c93c4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(Avatar.__post_init__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c383666d0a24d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "parser = argparse.ArgumentParser(\n",
    "    \"Use RL agent (DDPG or RDPG) with tensorflow backend for EOS with coast-down activated \"\n",
    "    \"and expected velocity in 3 seconds\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbeb52937fd1b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "parser.add_argument(\n",
    "    \"-v\",\n",
    "    \"--vehicle\",\n",
    "    type=str,\n",
    "    default=\"VB7_FIELD\",\n",
    "    help=\"vehicle ID like 'VB7' or 'MP3' or VIN 'HMZABAAH1MF011055'\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cd563ab9af818b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "parser.add_argument(\n",
    "    \"-d\",\n",
    "    \"--driver\",\n",
    "    type=str,\n",
    "    default=\"wang-kai\",\n",
    "    help=\"driver ID like 'longfei.zheng' or 'jiangbo.wei'\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0e65f53fc1152b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "parser.add_argument(\n",
    "    \"-i\",\n",
    "    \"--interface\",\n",
    "    type=str,\n",
    "    default=\"can_udp_svc\",\n",
    "    help=\"url for remote can server, e.g. \"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f0806f755c589c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "parser.add_argument(\n",
    "    \"-t\",\n",
    "    \"--trip\",\n",
    "    type=str,\n",
    "    default=\"local_udp\",\n",
    "    help=\"trip messenger, url or name, e.g. rocket_cloud, local_udp\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf333c8f48f69055",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "parser.add_argument(\n",
    "    \"-c\",\n",
    "    \"--control\",\n",
    "    type=str,\n",
    "    default=\"UDP\",\n",
    "    help=\"HMI Control Interface: \"\n",
    "         \"'RMQ' for mobile phone (using rocketmq for training/assessment); \"\n",
    "         \"'UDP' for local hmi (using loopback tcp for training/assessment); \"\n",
    "         \"'DUMMY' for non-interaction for inference only and testing purpose\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da43afaa4d885446",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "parser.add_argument(\n",
    "    \"-a\",\n",
    "    \"--agent\",\n",
    "    type=str,\n",
    "    default=\"ddpg\",\n",
    "    help=\"RL agent choice: 'ddpg' for DDPG; 'rdpg' for Recurrent DPG\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3837b4b505f0edfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "parser.add_argument(\n",
    "    \"-r\",\n",
    "    \"--resume\",\n",
    "    default=False,\n",
    "    help=\"resume the last training with restored model, checkpoint and pedal map\",\n",
    "    action=\"store_true\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a0468887807bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "parser.add_argument(\n",
    "    \"-l\",\n",
    "    \"--learning\",\n",
    "    default=True,\n",
    "    help=\"True for learning , with model update and training. False for inference only\",\n",
    "    action=\"store_true\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0cdf8f3f688174",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "parser.add_argument(\n",
    "    \"-p\",\n",
    "    \"--path\",\n",
    "    type=str,\n",
    "    default=\".\",\n",
    "    help=\"relative path to be saved, for create sub-folder for different drivers\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b376d679b1db156",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "parser.add_argument(\n",
    "    \"-o\",\n",
    "    \"--output\",\n",
    "    type=str,\n",
    "    default=\"mongo_local\",\n",
    "    help=\"pool selection for data storage, \"\n",
    "         \"url for mongodb server in format usr:password@host:port, e.g. admint:y02ydhVqDj3QFjT@10.10.0.4:23000, \"\n",
    "         \"or simply name with synced default config, e.g. mongo_cluster, mongo_local; \"\n",
    "         \"if specified as path name, use dask local under proj_root/data folder or cluster\",\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c789852",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "parser.add_argument(\n",
    "    \"--watchdog_nap_time\",\n",
    "    type=str,\n",
    "    default=\"600\",  # Default is  10 minutes\n",
    "    help=\"nap time for watchdog, \"\n",
    "         \"An internal watch dog will count the failures of input frame capturing,\"\n",
    "         \"if capture OR flash fails for the given times within the given nap time,\"\n",
    "\t\t \"default is 10 minutes or 600 seconds,\"\n",
    "         \"system will exit\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f3688c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "parser.add_argument(\n",
    "    \"--watchdog_capture_error_upper_bound\",\n",
    "    type=str,\n",
    "    default=\"30\",\n",
    "    help=\"Upper bound times for capture error, \"\n",
    "         \"An internal watch dog will count the failures of input frame capturing,\"\n",
    "         \"if capture fails for the given times,\"\n",
    "         \"system will exit\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f715bbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#| export\n",
    "parser.add_argument(\n",
    "    \"--watchdog_flash_error_upper_bound\",\n",
    "    type=str,\n",
    "    default=\"30\",\n",
    "    help=\"Upper bound times for flashing error, \"\n",
    "         \"An internal watch dog will count the failures of flashing,\"\n",
    "         \"if flash fails for the given times,\"\n",
    "         \"system will exit\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce6a9ebf44c215c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| output: true\n",
    "\n",
    "class C:\n",
    "    pass\n",
    "\n",
    "\n",
    "c = C()\n",
    "# parser.parse_args(args=['-v', 'VB7_FIELD'], namespace=c)\n",
    "# parser.parse_args(args=['-d', 'wang-kai'], namespace=c)\n",
    "# parser.parse_args(args=['-i', 'can_udp_svc'], namespace=c)\n",
    "# parser.parse_args(args=['-t', 'local_udp'], namespace=c)\n",
    "# parser.parse_args(args=['-c', 'UDP'], namespace=c)\n",
    "# parser.parse_args(args=['-a', 'ddpg'], namespace=c)\n",
    "# parser.parse_args(args=['-r'], namespace=c)\n",
    "# parser.parse_args(args=['-l'], namespace=c)\n",
    "# parser.parse_args(args=['-p', '.'], namespace=c)\n",
    "# parser.parse_args(args=['-o', 'mongo_local'], namespace=c)\n",
    "args = parser.parse_args(\n",
    "    args=['-v', 'VB7_FIELD', \n",
    "    '-d', 'wang-kai', \n",
    "    '-i', 'can_udp_svc', \n",
    "    '-t', 'local_udp', \n",
    "    '-c', 'UDP', \n",
    "    '-a', 'ddpg', \n",
    "    '-l', \n",
    "    '-p', '.', \n",
    "    '-o', 'mongo_local', \n",
    "    '--watchdog_nap_time', '10', # test with 10 seconds nap time\n",
    "    '--watchdog_capture_error_upper_bound', '1',  # test with 1 failuire, since no hardware is connected\n",
    "    '--watchdog_flash_error_upper_bound', '1' ], namespace=c)    # test with 1 failuire, since no hardware is connected\n",
    "#| output: true\n",
    "args.__dict__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74f419c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6482c7759ebe90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def main(args: argparse.Namespace) -> None:\n",
    "    \n",
    "    \"\"\"\n",
    "    Description: main function to start the Avatar\n",
    "    \"\"\"\n",
    "    # set up logging\n",
    "    # set up data folder (logging, checkpoint, table)\n",
    " \n",
    "    # set up data folder (logging, checkpoint, table)\n",
    "    try:\n",
    "        truck: Union[TruckInField, TruckInCloud] = str_to_truck(args.vehicle)\n",
    "    except KeyError:\n",
    "        raise KeyError(f\"vehicle {args.vehicle} not found in config file\")\n",
    "    else:\n",
    "        print(f\"Vehicle found. vid:{truck.vid}, vin: {truck.vin}.\")\n",
    "\n",
    "    try:\n",
    "        driver: Driver = str_to_driver(args.driver)\n",
    "    except KeyError:\n",
    "        raise KeyError(f\"driver {args.driver} not found in config file\")\n",
    "    else:\n",
    "        print(f\"Driver found. pid:{driver.pid}, name: {driver.name}.\")\n",
    "\n",
    "    # remotecan_srv: str = 'can_intra'\n",
    "    try:\n",
    "        can_server = str_to_can_server(args.interface)\n",
    "    except KeyError:\n",
    "        raise KeyError(f\"can server {args.interface} not found in config file\")\n",
    "    else:\n",
    "        print(f\"CAN Server found: {can_server.server_name}\")\n",
    "\n",
    "    try:\n",
    "        trip_server = str_to_trip_server(args.trip)\n",
    "    except KeyError:\n",
    "        raise KeyError(f\"trip server {args.web} not found in config file\")\n",
    "    else:\n",
    "        print(f\"Trip Server found: {trip_server.server_name}\")\n",
    "\n",
    "    assert args.agent in [\"ddpg\", \"rdpg\"], \"agent must be either ddpg or rdpg\"\n",
    "\n",
    "    if args.resume:\n",
    "        data_root = proj_root.joinpath(\"data/\" + truck.vin + \"-\" + driver.pid).joinpath(\n",
    "            args.path\n",
    "        )\n",
    "    else:  # from scratch\n",
    "        data_root = proj_root.joinpath(\n",
    "            \"data/scratch/\" + truck.vin + \"-\" + driver.pid\n",
    "        ).joinpath(args.path)\n",
    "\n",
    "    logger, dict_logger = set_root_logger(\n",
    "        name=\"eos\",\n",
    "        data_root=data_root,\n",
    "        agent=args.agent,\n",
    "        tz = truck.site.tz,\n",
    "        truck = truck.vid,\n",
    "        driver = driver.pid\n",
    "    )\n",
    "    logger.info(f\"{{'header': 'Start Logging'}}\", extra=dict_logger)\n",
    "\n",
    "    if args.agent == \"ddpg\":\n",
    "        agent: DDPG = DDPG(\n",
    "            _coll_type=\"RECORD\",\n",
    "            _hyper_param=HyperParamDDPG(),\n",
    "            _truck=truck,\n",
    "            _driver=driver,\n",
    "            _pool_key=args.output,\n",
    "            _data_folder=str(data_root),\n",
    "            _infer_mode=(not args.learning),\n",
    "            _resume=args.resume,\n",
    "            logger=logger,\n",
    "            dict_logger=dict_logger,\n",
    "        )\n",
    "    else:  # args.agent == 'rdpg':\n",
    "        agent: RDPG = RDPG(  # type: ignore\n",
    "            _coll_type=\"EPISODE\",\n",
    "            _hyper_param=HyperParamRDPG(),\n",
    "            _truck=truck,\n",
    "            _driver=driver,\n",
    "            _pool_key=args.output,\n",
    "            _data_folder=str(data_root),\n",
    "            _infer_mode=(not args.learning),\n",
    "            _resume=args.resume,\n",
    "            logger=logger,\n",
    "            dict_logger=dict_logger,\n",
    "        )\n",
    "\n",
    "    try:\n",
    "        avatar = Avatar(\n",
    "            _truck=truck,\n",
    "            _driver=driver,\n",
    "            _agent=agent,\n",
    "            _can_server=can_server,\n",
    "            _trip_server=trip_server,\n",
    "            logger=logger,\n",
    "            dict_logger=dict_logger,\n",
    "            _resume=args.resume,\n",
    "            _infer_mode=(not args.learning),\n",
    "            data_root=data_root,\n",
    "        )\n",
    "    except TypeError as e:\n",
    "        logger.error(\n",
    "            f\"{{'header': 'Project Exception TypeError', \" f\"'exception': '{e}'}}\",\n",
    "            extra=dict_logger,\n",
    "        )\n",
    "        sys.exit(1)\n",
    "    except Exception as e:\n",
    "        logger.error(\n",
    "            f\"{{'header': 'main Exception', \" f\"'exception': '{e}'}}\",\n",
    "            extra=dict_logger,\n",
    "        )\n",
    "        sys.exit(1)\n",
    "\n",
    "    # initialize dataflow: pipelines, sync events among the threads\n",
    "    observe_pipeline = Pipeline[pd.DataFrame](\n",
    "        maxsize=3\n",
    "    )  # pipeline for observations (type dataframe)\n",
    "    flash_pipeline = Pipeline[pd.DataFrame](\n",
    "        maxsize=3\n",
    "    )  # pipeline for flashing torque tables (type dataframe)\n",
    "    start_event = Event()\n",
    "    stop_event = Event()\n",
    "    interrupt_event = Event()\n",
    "    exit_event = Event()\n",
    "    flash_event = Event()\n",
    "\n",
    "    logger.info(f\"{{'header': 'main Thread Pool starts!'}}\", extra=dict_logger)\n",
    "\n",
    "    # Gracefulkiller instance can be created only in the main thread!\n",
    "    killer = GracefulKiller(exit_event)\n",
    "    with concurrent.futures.ThreadPoolExecutor(\n",
    "        max_workers=2, thread_name_prefix='Avatar'\n",
    "    ) as executor:\n",
    "        executor.submit(\n",
    "            avatar.vehicle_interface.ignite,  # observe thread (spawns 4 threads for input, HMI and output)\n",
    "            observe_pipeline,  # input port; output\n",
    "            flash_pipeline,  # out port; input\n",
    "            start_event,\n",
    "            stop_event,\n",
    "            interrupt_event,\n",
    "            flash_event,\n",
    "            exit_event,\n",
    "            float(args.watchdog_nap_time),\n",
    "            int(args.watchdog_capture_error_upper_bound),\n",
    "            int(args.watchdog_flash_error_upper_bound),\n",
    "        )\n",
    "\n",
    "        executor.submit(\n",
    "            avatar.cruncher.filter,  # data crunch thread\n",
    "            observe_pipeline,  # output port; input\n",
    "            flash_pipeline,  # input port; output\n",
    "            start_event,\n",
    "            stop_event,\n",
    "            interrupt_event,\n",
    "            flash_event,\n",
    "            exit_event,\n",
    "        )\n",
    "\n",
    "    logger.info(f\"{{'header': 'Start main Thread Pool dies!'}}\", extra=dict_logger)\n",
    "    # default behavior is \"observe\" will start and send out all the events to orchestrate other three threads.\n",
    "    logger.info(\"Program exit!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a259afc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d31e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp ../tspace/res/tbox/xcp_driver/json/example.json /dev/shm/out.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fa37f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "main(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62b6ccf64cbd4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "if __name__ == \"__main__\" and \"__file__\" in globals():  # in order to be compatible for both script and notebnook\n",
    "    \"\"\"\n",
    "    ## Setup\n",
    "    \"\"\"\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    main(args)\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192eed91d531797f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
